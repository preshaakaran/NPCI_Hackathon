{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnHjiFLyRwcx",
        "outputId": "f0366797-5f49-4075-b037-fb47378c57fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7t3YoM_QLc9",
        "outputId": "5e8af0ba-f2ac-4547-e18e-7aab91062091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest MAE: 2.390249076524137\n",
            "Random Forest RMSE: 2.9511907268763444\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 27.3801 - val_loss: 12.7182\n",
            "Epoch 2/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 12.5528 - val_loss: 10.7808\n",
            "Epoch 3/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 10.8185 - val_loss: 10.3431\n",
            "Epoch 4/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 11.4146 - val_loss: 9.7547\n",
            "Epoch 5/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.9236 - val_loss: 9.5411\n",
            "Epoch 6/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.4513 - val_loss: 9.6276\n",
            "Epoch 7/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.4220 - val_loss: 9.3238\n",
            "Epoch 8/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 10.1721 - val_loss: 9.3656\n",
            "Epoch 9/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 10.3755 - val_loss: 9.2902\n",
            "Epoch 10/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 9.6258 - val_loss: 9.6075\n",
            "Epoch 11/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 9.3716 - val_loss: 9.5794\n",
            "Epoch 12/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.3669 - val_loss: 9.8069\n",
            "Epoch 13/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.3993 - val_loss: 9.4364\n",
            "Epoch 14/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.4115 - val_loss: 9.2190\n",
            "Epoch 15/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10.0936 - val_loss: 9.2836\n",
            "Epoch 16/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.6545 - val_loss: 9.2849\n",
            "Epoch 17/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.9605 - val_loss: 9.3785\n",
            "Epoch 18/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.4303 - val_loss: 9.5080\n",
            "Epoch 19/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.2825 - val_loss: 9.3011\n",
            "Epoch 20/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.2612 - val_loss: 9.2987\n",
            "Epoch 21/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.7950 - val_loss: 9.4660\n",
            "Epoch 22/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.8073 - val_loss: 9.4967\n",
            "Epoch 23/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.5418 - val_loss: 9.5904\n",
            "Epoch 24/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.8819 - val_loss: 9.7828\n",
            "Epoch 25/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.4666 - val_loss: 9.4201\n",
            "Epoch 26/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.9554 - val_loss: 9.1747\n",
            "Epoch 27/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.7550 - val_loss: 10.0031\n",
            "Epoch 28/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.3314 - val_loss: 9.2041\n",
            "Epoch 29/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.6150 - val_loss: 10.3394\n",
            "Epoch 30/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.6935 - val_loss: 10.1472\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step\n",
            "LSTM MAE: 2.762392044067383\n",
            "LSTM RMSE: 3.1854646953972914\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import gym\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv('/content/cleaned_toll_data.csv')\n",
        "\n",
        "# Ensure proper data types\n",
        "df = df.select_dtypes(include=[np.number]).dropna()\n",
        "\n",
        "# ==========================\n",
        "# 1. Random Forest for Queue Prediction\n",
        "# ==========================\n",
        "X = df.drop(columns=['queue_length'])  # Features\n",
        "y = df['queue_length']  # Target\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hyperparameter-tuned Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"Random Forest MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"Random Forest RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "# ==========================\n",
        "# 2. LSTM for Time-Series Queue Forecasting\n",
        "# ==========================\n",
        "time_series_data = df[['queue_length']].values\n",
        "timesteps = 10\n",
        "\n",
        "def create_sequences(data, timesteps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - timesteps):\n",
        "        X.append(data[i:i+timesteps])\n",
        "        y.append(data[i+timesteps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(time_series_data, timesteps)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Improved LSTM Model\n",
        "model = Sequential([\n",
        "    LSTM(64, activation='relu', return_sequences=True, input_shape=(timesteps, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate LSTM\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"LSTM MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"LSTM RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "# ==========================\n",
        "# 3. Deep Q-Learning for Toll Optimization\n",
        "# ==========================\n",
        "class TollEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(TollEnv, self).__init__()\n",
        "        self.state = np.array([5, 10])  # [Queue Length, Toll Booths Open]\n",
        "        self.action_space = gym.spaces.Discrete(3)  # 0: Open, 1: Close, 2: Maintain\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=100, shape=(2,), dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 0:\n",
        "            self.state[1] = min(self.state[1] + 1, 9)  # Open booth, max 9\n",
        "        elif action == 1:\n",
        "            self.state[1] = max(self.state[1] - 1, 0) # Close booth, min 0\n",
        "        self.state[0] = max(0, self.state[0] - self.state[1])  # Reduce queue\n",
        "        reward = -self.state[0]  # Less queue is better\n",
        "        return self.state, reward, False, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.array([5, 10])\n",
        "        return self.state\n",
        "\n",
        "env = TollEnv()\n",
        "\n",
        "# # Deep Q-Network (DQN) Model\n",
        "# dqn_model = Sequential([\n",
        "#     Dense(24, activation='relu', input_shape=(2,)),\n",
        "#     Dense(24, activation='relu'),\n",
        "#     Dense(env.action_space.n, activation='linear')\n",
        "# ])\n",
        "# dqn_model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
        "\n",
        "# # Training DQN\n",
        "# memory = deque(maxlen=2000)\n",
        "# gamma, epsilon = 0.95, 1.0\n",
        "# epsilon_min, epsilon_decay = 0.01, 0.995\n",
        "\n",
        "# for episode in range(1000):\n",
        "#     state = env.reset()\n",
        "#     state = np.reshape(state, [1, 2])\n",
        "\n",
        "#     for step in range(100):\n",
        "#         # Epsilon-greedy action selection\n",
        "#         if np.random.rand() <= epsilon:\n",
        "#             action = env.action_space.sample()\n",
        "#         else:\n",
        "#             action = np.argmax(dqn_model.predict(state)[0])\n",
        "\n",
        "#         next_state, reward, done, _ = env.step(action)\n",
        "#         next_state = np.reshape(next_state, [1, 2])\n",
        "\n",
        "#         # Store experience\n",
        "#         memory.append((state, action, reward, next_state))\n",
        "\n",
        "#         state = next_state\n",
        "\n",
        "#     # Train DQN using replay memory\n",
        "#     if len(memory) > 32:\n",
        "#         minibatch = random.sample(memory, 32)\n",
        "#         for state, action, reward, next_state in minibatch:\n",
        "#             target = reward + gamma * np.amax(dqn_model.predict(next_state)[0])\n",
        "#             target_f = dqn_model.predict(state)\n",
        "#             target_f[0][action] = target\n",
        "#             dqn_model.fit(state, target_f, epochs=1, verbose=0)\n",
        "\n",
        "#     # Reduce exploration\n",
        "#     if epsilon > epsilon_min:\n",
        "#         epsilon *= epsilon_decay\n",
        "\n",
        "# print(\"DQN Training Complete!\")\n",
        "\n"
      ]
    }
  ]
}